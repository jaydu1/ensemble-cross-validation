{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Cross-Validation for Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "n_cores = int(8)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = f\"{n_cores}\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = f\"{n_cores}\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = f\"{n_cores}\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = f\"{n_cores}\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = f\"{n_cores}\"\n",
    "os.environ[\"NUMBA_CACHE_DIR\"]='/tmp/numba_cache'\n",
    "\n",
    "import numpy as np\n",
    "from sklearn_ensemble_cv import reset_random_seeds\n",
    "\n",
    "reset_random_seeds(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make up some fake data for illustration. Below, the response is of dimension 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_regression(n_samples=300, n_features=200,\n",
    "                       n_informative=5, n_targets=2,\n",
    "                       random_state=0, shuffle=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility fitting function\n",
    "\n",
    "To facilitate the fitting and model selection of random forests, we define a function that takes in the data and returns the prediction values on test features.\n",
    "One can customize the function to return quantities they need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from sklearn_ensemble_cv import reset_random_seeds, Ensemble, ECV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def fit_rf(X, y, X_test=None, M=25, M_max=50,\n",
    "    # fixed parameters for bagging regressor\n",
    "    kwargs_ensemble={'verbose':1},\n",
    "    # fixed parameters for decision tree\n",
    "    kwargs_regr={'min_samples_split': 2},\n",
    "    # grid search parameters\n",
    "    grid_regr = {'max_depth': [6,7]},\n",
    "    grid_ensemble = {\n",
    "        'max_features':np.array([0.9,1.]),\n",
    "        'max_samples':np.array([0.6,0.7])},\n",
    "    ):\n",
    "\n",
    "    # Make sure y is 2D\n",
    "    y = y.reshape(-1, 1) if y.ndim == 1 else y\n",
    "\n",
    "    # Run ECV\n",
    "    res_ecv, info_ecv = ECV(\n",
    "        X, y, DecisionTreeRegressor, grid_regr, grid_ensemble, \n",
    "        kwargs_regr, kwargs_ensemble, \n",
    "        M=M, M0=M, M_max=M_max, return_df=True\n",
    "    )\n",
    "\n",
    "    # Replace the in-sample best parameter for 'n_estimators' with extrapolated best parameter\n",
    "    info_ecv['best_params_ensemble']['n_estimators'] = info_ecv['best_n_estimators_extrapolate']\n",
    "\n",
    "    # Fit the ensemble with the best CV parameters\n",
    "    regr = Ensemble(\n",
    "        estimator=DecisionTreeRegressor(**info_ecv['best_params_regr']),\n",
    "        **info_ecv['best_params_ensemble']).fit(X, y)\n",
    "        \n",
    "    # Predict\n",
    "    if X_test is None:\n",
    "        X_test = X\n",
    "    return regr.predict(X_test).reshape(-1, y.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple way to deal with multiple responses is through multitask learning, where we use all the responses for node splitting of decision trees. This is implemented in the `sklearn` package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5722.970560206186\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = fit_rf(X_train, y_train, X_test)\n",
    "\n",
    "# Print the mean squared error\n",
    "print(np.mean((y_test_pred - y_test)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can also fit a separate random forest for each response, as implemented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_rf_ind(X, Y, *args, **kwargs):\n",
    "    Y_hat = Parallel(n_jobs=-1)(delayed(fit_rf)(X, Y[:,j], *args, **kwargs)\n",
    "        for j in tqdm(range(Y.shape[1])))\n",
    "    Y_pred = np.concatenate(Y_hat, axis=-1)\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5489.074680557097\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = fit_rf_ind(X_train, y_train, X_test)\n",
    "\n",
    "# Print the mean squared error\n",
    "print(np.mean((y_test_pred - y_test)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the second approach gives better performance in this case.\n",
    "However, the first approach is more computationally efficient and may be preferred in practice, especially when the number of responses is large."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
